from transformers import pipeline
import gradio as gr

# Charger le mod√®le BlenderBot
chatbot = pipeline("text2text-generation", model="facebook/blenderbot-400M-distill")

# Contexte global
context = ""

# Fonction principale du chatbot
def mini_chatbot(user_message, history):
    global context

    # Cr√©er le texte avec historique
    input_text = context + f"\nUser: {user_message}\nBot: "
    
    # DEBUG : afficher le texte envoy√© au mod√®le
    print("\nüìù Input envoy√© au mod√®le :")
    print(input_text)
    print("-" * 60)

    try:
        # G√©n√©ration de r√©ponse
        response = chatbot(input_text, max_length=200, do_sample=True)[0]["generated_text"]

        # DEBUG : afficher la r√©ponse brute
        print("ü§ñ R√©ponse g√©n√©r√©e :", response)

        # Mettre √† jour le contexte
        context += f"\nUser: {user_message}\nBot: {response}"

    except Exception as e:
        print("‚ùå Erreur pendant la g√©n√©ration :", e)
        response = "Oops, something went wrong. Let's try again."

        # R√©initialiser le contexte en cas de plantage
        context = ""

    return response

# Fonction pour r√©initialiser le contexte via Gradio
def reset_chat():
    global context
    context = ""
    print("üîÑ Contexte r√©initialis√©.")
    return None

# Interface Gradio
demo_chatbot = gr.ChatInterface(
    fn=mini_chatbot,
    title="BlenderBot Chatbot ü§ñ",
    description="Chat with a BlenderBot-based conversational AI from Facebook."
)

# Attacher la fonction de reset au bouton de nettoyage
demo_chatbot.chatbot.clear_fn = reset_chat

# Lancer l‚Äôapplication
if __name__ == "__main__":
    demo_chatbot.launch()
