{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "20d9816968644e6b87ab3229fb51df84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85884b295b2d45b794c975bd39a0dfbd",
              "IPY_MODEL_a7fa897f7b0748b6b22c6a5d2d3f4fe0",
              "IPY_MODEL_3cde6f407c434c689707bd741c7f4c18"
            ],
            "layout": "IPY_MODEL_e34375ed0c3c4645812bf52f427ced77"
          }
        },
        "85884b295b2d45b794c975bd39a0dfbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e077762635ec442e8cb8b992ade9e2f3",
            "placeholder": "​",
            "style": "IPY_MODEL_85a8eb2bbdef4aceb7c3fae0fb609351",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a7fa897f7b0748b6b22c6a5d2d3f4fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db0088220b124d109e8a5655e59801fb",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83698769d7224238b5b21c857e1b7296",
            "value": 48
          }
        },
        "3cde6f407c434c689707bd741c7f4c18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3740902629f04d44bb50877a2d0ac757",
            "placeholder": "​",
            "style": "IPY_MODEL_0ea33261a9d540bca5f2d067d621d8c6",
            "value": " 48.0/48.0 [00:00&lt;00:00, 5.91kB/s]"
          }
        },
        "e34375ed0c3c4645812bf52f427ced77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e077762635ec442e8cb8b992ade9e2f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85a8eb2bbdef4aceb7c3fae0fb609351": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db0088220b124d109e8a5655e59801fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83698769d7224238b5b21c857e1b7296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3740902629f04d44bb50877a2d0ac757": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ea33261a9d540bca5f2d067d621d8c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "764cb9101d934cb892331e9462ae706c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5c8d15e3035406a8a50ef0a417a35ed",
              "IPY_MODEL_46315c2d6d2d4cfb8cbac5d8ab876629",
              "IPY_MODEL_83e7f82db6c1495c853205e286a0ffb4"
            ],
            "layout": "IPY_MODEL_97a1b62ca1d5431abfe48edb7c60df1e"
          }
        },
        "c5c8d15e3035406a8a50ef0a417a35ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8068a85963a45b58fb54251c97d5b52",
            "placeholder": "​",
            "style": "IPY_MODEL_3d84a3b4120b4d58a3b4b3aebaa83e51",
            "value": "vocab.txt: 100%"
          }
        },
        "46315c2d6d2d4cfb8cbac5d8ab876629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1948fd2ed860412faf82f092956c8988",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4231d33a153c4a9f89dab00243d33317",
            "value": 231508
          }
        },
        "83e7f82db6c1495c853205e286a0ffb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9eea0c865b72428cb07a6df158f1767f",
            "placeholder": "​",
            "style": "IPY_MODEL_8624e7569dbc452a9ed6e98443844122",
            "value": " 232k/232k [00:00&lt;00:00, 14.9MB/s]"
          }
        },
        "97a1b62ca1d5431abfe48edb7c60df1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8068a85963a45b58fb54251c97d5b52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d84a3b4120b4d58a3b4b3aebaa83e51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1948fd2ed860412faf82f092956c8988": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4231d33a153c4a9f89dab00243d33317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9eea0c865b72428cb07a6df158f1767f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8624e7569dbc452a9ed6e98443844122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15fbce8a17a74fac8cf1e04a8f581349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1c89ea7413646fbbf65537669f898a8",
              "IPY_MODEL_87d0824fa766486fbb53a0b20c1f8639",
              "IPY_MODEL_41dc3e98c02c4564b7ce7f3d6b12d26c"
            ],
            "layout": "IPY_MODEL_c070073fc44840b68fafb36e1c7a01ff"
          }
        },
        "f1c89ea7413646fbbf65537669f898a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d47c0ae4f83a42228ac04bd948a15f77",
            "placeholder": "​",
            "style": "IPY_MODEL_c7b50ae81b8e4e8b95626f4f2ffc1bcb",
            "value": "tokenizer.json: 100%"
          }
        },
        "87d0824fa766486fbb53a0b20c1f8639": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8e31c7ca73f426e82984c7c7f702642",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22434dd4e1d543d48c37482fd5f5a9de",
            "value": 466062
          }
        },
        "41dc3e98c02c4564b7ce7f3d6b12d26c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_486d37a86447429080ac1e3eb6ea7237",
            "placeholder": "​",
            "style": "IPY_MODEL_e73283604bb042819f39ffd69aee65bc",
            "value": " 466k/466k [00:00&lt;00:00, 22.8MB/s]"
          }
        },
        "c070073fc44840b68fafb36e1c7a01ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d47c0ae4f83a42228ac04bd948a15f77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7b50ae81b8e4e8b95626f4f2ffc1bcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8e31c7ca73f426e82984c7c7f702642": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22434dd4e1d543d48c37482fd5f5a9de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "486d37a86447429080ac1e3eb6ea7237": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e73283604bb042819f39ffd69aee65bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2edd2acaf2c14b0580057a3509bffe5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73b46bb3ccdf4649be3fd00c22e7b1c7",
              "IPY_MODEL_3fdb37518ecb4862bfd1836fd6802da3",
              "IPY_MODEL_51c842674aaf4c23ad6dce997b4b7b37"
            ],
            "layout": "IPY_MODEL_50d1443eff334257a9093411110324d9"
          }
        },
        "73b46bb3ccdf4649be3fd00c22e7b1c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84173d0e52c64ab3af3b53bafc813d2a",
            "placeholder": "​",
            "style": "IPY_MODEL_36441753c3b746cb9394b9078f8bc83a",
            "value": "config.json: 100%"
          }
        },
        "3fdb37518ecb4862bfd1836fd6802da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03339e2543374788bb82c1d6adb2c2f3",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed75c20d30e948a8a653ee260d30c983",
            "value": 570
          }
        },
        "51c842674aaf4c23ad6dce997b4b7b37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89c08d889cff405f8dae31f3d921037d",
            "placeholder": "​",
            "style": "IPY_MODEL_4bbd6332bd8a4ab1a02fe6331ff54889",
            "value": " 570/570 [00:00&lt;00:00, 70.1kB/s]"
          }
        },
        "50d1443eff334257a9093411110324d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84173d0e52c64ab3af3b53bafc813d2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36441753c3b746cb9394b9078f8bc83a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03339e2543374788bb82c1d6adb2c2f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed75c20d30e948a8a653ee260d30c983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89c08d889cff405f8dae31f3d921037d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bbd6332bd8a4ab1a02fe6331ff54889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a4562ea2d84443c9ae6a8743c73b822": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ec08f4eed3b4e2c9d7aafda2617639d",
              "IPY_MODEL_cbd4b29338ad46278d78855c6becfdd2",
              "IPY_MODEL_9c3daaeff870470ea69c878c241ad7ff"
            ],
            "layout": "IPY_MODEL_a77442671a544803a3ab588853aee499"
          }
        },
        "4ec08f4eed3b4e2c9d7aafda2617639d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d1f1f2135ca4cc5b57a950de6262064",
            "placeholder": "​",
            "style": "IPY_MODEL_81ac7331c9b84c85a086012979dfb3e1",
            "value": "model.safetensors: 100%"
          }
        },
        "cbd4b29338ad46278d78855c6becfdd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2571a2577fb5473d904bf4319f734259",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_050d3e0cb38e46a0ab86b6c43d1e261e",
            "value": 440449768
          }
        },
        "9c3daaeff870470ea69c878c241ad7ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b575db704c246b0bcea606c90b8e664",
            "placeholder": "​",
            "style": "IPY_MODEL_385e400a7cce49f6bdd68a1786f75b14",
            "value": " 440M/440M [00:01&lt;00:00, 362MB/s]"
          }
        },
        "a77442671a544803a3ab588853aee499": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d1f1f2135ca4cc5b57a950de6262064": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81ac7331c9b84c85a086012979dfb3e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2571a2577fb5473d904bf4319f734259": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "050d3e0cb38e46a0ab86b6c43d1e261e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b575db704c246b0bcea606c90b8e664": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "385e400a7cce49f6bdd68a1786f75b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hzL2CudtY7Uy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🧠 Introduction — AI-Generated Text Detector using a GAN\n",
        "\n",
        "Generative Adversarial Networks (GANs) are a powerful class of deep learning models introduced by Ian Goodfellow in 2014. They are based on a very simple yet brilliant idea: **two neural networks compete against each other in a zero-sum game**.\n",
        "\n",
        "A GAN consists of two main components:\n",
        "- **The Generator**: its role is to produce data that looks as realistic as possible (in our case, text embeddings that resemble those produced by humans or by AI).\n",
        "- **The Discriminator**: its task is to distinguish between real data (human-written text) and generated data (AI-written text).\n",
        "\n",
        "Over time, the generator improves in “fooling” the discriminator, while the discriminator becomes more skilled at detecting generated content. This adversarial training loop enables GANs to learn highly expressive data representations.\n",
        "\n",
        "---\n",
        "\n",
        "### 🎯 Project Objective\n",
        "\n",
        "In this challenge, we’ll leverage this architecture to **build a detector for AI-generated text**. Specifically:\n",
        "- We'll use a pre-trained **BERT** model to encode the input texts.\n",
        "- We'll train a **generator** to produce embeddings that resemble those from AI-generated text.\n",
        "- We'll train a **discriminator** to decide whether an embedding comes from a human or an AI-written text.\n",
        "\n",
        "We’ll evaluate the discriminator’s performance using the **AUC (Area Under the Curve)** score, which is a key metric for binary classification tasks like this one.\n",
        "\n",
        "This project is a great opportunity to deepen our understanding of GANs while building a practical system for **detecting AI-generated content**—a growing concern in today’s generative AI landscape.\n",
        "\n",
        "---\n",
        "\n",
        "📌 *Note: this challenge uses a hybrid approach that combines GANs with Transformer-based architectures to leverage both semantic encoding and adversarial training.*\n"
      ],
      "metadata": {
        "id": "_dLeR4M3ZeXP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AnU__K2rd3Fk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import string\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import BertConfig\n",
        "from transformers.models.bert.modeling_bert import BertEncoder\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Nettoyer tous les fichiers du dossier /content (sauf les dossiers système)\n",
        "for f in os.listdir(\"/content\"):\n",
        "    path = f\"/content/{f}\"\n",
        "    if os.path.isfile(path):\n",
        "        os.remove(path)\n",
        "\n",
        "# Lancer l’upload interactif\n",
        "print(\" Veuillez téléverser vos fichiers maintenant.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Afficher uniquement les noms des fichiers\n",
        "print(\"\\n Fichiers téléversés :\")\n",
        "for fname in uploaded.keys():\n",
        "    print(fname)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "4ocwuBU9eXkE",
        "outputId": "ba6dd4a8-96a8-4ed3-8c3f-457a23619edd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Veuillez téléverser vos fichiers maintenant.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-065eef1f-3ec3-48f2-aea4-caafb5dc73ff\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-065eef1f-3ec3-48f2-aea4-caafb5dc73ff\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sample_submission.csv to sample_submission.csv\n",
            "Saving test_essays.csv to test_essays.csv\n",
            "Saving train_essays.csv to train_essays.csv\n",
            "Saving train_prompts.csv to train_prompts.csv\n",
            "\n",
            " Fichiers téléversés :\n",
            "sample_submission.csv\n",
            "test_essays.csv\n",
            "train_essays.csv\n",
            "train_prompts.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📥 Load Data Files\n",
        "\n",
        "In this step, we load all the CSV files required for our project:\n",
        "- `train_essays.csv`: training texts with associated labels (AI or human)\n",
        "- `test_essays.csv`: unlabeled texts to predict on\n",
        "- `train_prompts.csv`: corresponding prompts used to generate or inspire the texts\n",
        "- `sample_submission.csv`: format for submitting predictions\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XEdnKPQZalfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_PATH = \"/content/train_essays.csv\"\n",
        "TEST_PATH = \"/content/test_essays.csv\"\n",
        "PROMPT_PATH = \"/content/train_prompts.csv\"\n",
        "SUB_PATH = \"/content/sample_submission.csv\"\n",
        "\n",
        "\n",
        "src_train = pd.read_csv(TRAIN_PATH)\n",
        "src_test = pd.read_csv(TEST_PATH)\n",
        "src_prompt = pd.read_csv(PROMPT_PATH)\n",
        "src_sub = pd.read_csv(SUB_PATH)"
      ],
      "metadata": {
        "id": "43CI4MStJpUR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(src_train.shape, src_test.shape, src_prompt.shape, src_sub.shape)\n",
        "print(\"Extrait du train :\")\n",
        "src_train.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "-Qzi0vEwNdhh",
        "outputId": "3ee78629-53d6-499b-ebbd-4a8c391cc128"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1378, 4) (3, 3) (2, 4) (3, 2)\n",
            "Extrait du train :\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            id  prompt_id                                               text  \\\n",
              "1101  c8b89dd4          1  Dear, state senator I think we should change t...   \n",
              "88    135b769a          1  To the State Senate, Addressing my ultimate op...   \n",
              "468   5cd6a57e          0  Cars our main source for travel, what we depen...   \n",
              "38    08157ec0          0  To access what one needs in the world today, m...   \n",
              "177   228a014b          1  Dear my Senator, whats the point in voting if ...   \n",
              "\n",
              "      generated  \n",
              "1101          0  \n",
              "88            0  \n",
              "468           0  \n",
              "38            0  \n",
              "177           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a2f2c106-3aa8-4f80-9ebf-c483e9b47a21\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>text</th>\n",
              "      <th>generated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1101</th>\n",
              "      <td>c8b89dd4</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear, state senator I think we should change t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>135b769a</td>\n",
              "      <td>1</td>\n",
              "      <td>To the State Senate, Addressing my ultimate op...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>468</th>\n",
              "      <td>5cd6a57e</td>\n",
              "      <td>0</td>\n",
              "      <td>Cars our main source for travel, what we depen...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>08157ec0</td>\n",
              "      <td>0</td>\n",
              "      <td>To access what one needs in the world today, m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>228a014b</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear my Senator, whats the point in voting if ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2f2c106-3aa8-4f80-9ebf-c483e9b47a21')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a2f2c106-3aa8-4f80-9ebf-c483e9b47a21 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a2f2c106-3aa8-4f80-9ebf-c483e9b47a21');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-39f508e8-3281-4ca7-93a7-c756bda40740\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-39f508e8-3281-4ca7-93a7-c756bda40740')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-39f508e8-3281-4ca7-93a7-c756bda40740 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"src_train\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"135b769a\",\n          \"228a014b\",\n          \"5cd6a57e\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"To the State Senate, Addressing my ultimate opinion, I believe should change the vote of the Electoral College into a popularbased vote. Examining a large number of articles which has fulfilled my understanding of the Electoral College including the process and diverse opinions of the Electoral College. This essay will propose the counterclaim the opposing side of why we should not change the process of vote in the United States and address the counterclaim of why the Electoral College should be changed to a popular vote. In order to understand each side, we must first comprehend the process behind the Electoral College. Posner stated, \\\"...it is the electors who elect the president, not the people. When you vote for a presidential candidate you're actually voting for a slate of electors\\\" 3. This is the one of the most important concepts to understand in the process of the Electoral College, for we must know that each vote you compose, you vote for a slate of electors, who will basically vote for their candidate. \\\"The Electoral College is a process, not a place\\\" Office of the Federal Register, 1. This lets us put down a foundation of the Electoral College as well.\\n\\nAccording to Plumer, \\\"Perhaps most worrying is the prospect of a tie in the electoral vote\\\" 2. This indicates how the tie could carry the vote to the House of Representatives, where the federal judgement takes place of voting for the president. Not only this, but Plumer also stated,\\\"Because each state casts only one vote, the single representative from Wyoming, representing 500,000 voters, would have as much say as the 55 representatives from California, who represent 35 million voters\\\" 2. This statement from Plumer strongly imposes the knowledge that this tie carried to the House of Representatives would hardly reflect the will of the people due to census of the population. This article highlighted that the vote in 2000 where the system actually seemed to flaw when Gore recieved a higher popular vote than Bush, however, Bush received a higher electoral vote. In this situation, is this truly fair? This example dipicts how the vote is truly determined on a group of people from the population rather than a vote depending upon the entire nation itself. Plumer stated, \\\"...the electoral college is unfair to voters...swing states...\\\" 2. This brings us the idea of the swing states and how the candidates in the winnertakeall system do not bother to go to states they know that they have no chance of winning, which harshly reveals that some votes may be biased from the electors ignoring other states. \\\"It's official: The electoral college is unfair, outdated, and irrational\\\" Plumer,2. This concludes how biased the Electoral College can be when it comes to ties, representatives, the disaster factor, and a great multitude of concepts and situations where the Electoral College has flawed.\\n\\nNow, I have also read articles that contained letters that emphasized why the Electoral College should not be changed in any way, due to the \\\"...Certainty of Outcome...Everyone's President...Swing States...Big States... Avoid RunOff Elections...\\\" Posner, 3. These subtitles are points that Posner focused on that he believes can persuade why the Electoral College is somewhat efficient. In each of these points, I can counter that the certainty of the vote is false due to the fiasco of Gore and Bush in 2000, as well as the concept of the House of Representatives that I mentioned earlier as well. In the factor that Posner mentioned in his point of everyone's president, I do not find this very accurate due to the reason that our vote relies on a slate of electors, not us entirely, as it would in a popular vote. In swing states, it mentions in the article of Plumer that a winnertakesall method is unfair to voters because electors ignore states that they do not have confidence in winning the vote. A major point that I disagree with would be the point that Posner pointed out with Big States, where he mentioned that,\\\"The Electoral College restores some of the weight in the political balance that large states by population lose by virtue of the malapportionment of the Senate decreed in the Constitution...\\\" 3. In this, I would argue that this is unfair, because of the inequality of representatives due to population, which is not the voter's decision. In the statement of Avoid Runoff Elections, Posner states that, \\\"The Electoral College avoids that problem of elections in which no candidate receives a majority of the votes cast\\\" 3. I find this false due to the reason that the Electoral College is based on a different amount of voters and electors in each state, which in turn is viewed unfair because there is a factor of the swing states once again, explains that some electors choose states over another which lets us show how unfair the Electoral College is, generally speaking.\\n\\nIn conclusion, we have established our opinion on why the vote should be changed into a popular vote instead of the Electoral College due to a myriad of concepts, such as the disaster factor in 2000, why swingstates are unfair, the prospect of a tie in the electoral vote, just to reveal the tip of the iceberg in our arguments of understanding why the Electoral College is biased, irrational, and unfair. We have also covered the counterclaims and reasoned them with logic, reality, and true rationality of why the Electoral College shoud be abolished in the vote of the President of the United States of America.\",\n          \"Dear my Senator, whats the point in voting if our vote may not even count?\\n\\nIn the Electoral college people citizens vote for a slate of electors who then later go and vote for president. However, sometimes it doesn work that way. The electors are not obligated to choose the president that the people want. The Electoral college is corrupt and needs to go away.\\n\\nThe people of America dont like the Electoral college and want something new. Stated in source 2, \\\" gallop poll in 2000, taken shortly after Al Gorethanks the quirks of the electoral college won the popular vote but lost the presidency, over 60 percent off voters would prefer a dirt election to the kind we have now.\\\" In short, people were so unhappy with the election and the way it ended. people would rather have direct voting than to continue with an Electoral college.\\n\\nThe Electors in the Electoral college arnt always innocent. They can lie, cheat, they go behind the backs of the states citizens and not even vote for who the citizens want. In 1960, segregationists in the louisiana legislature tried to get rid of the democratic electors. They wanted to replace them with people who would oppose John F Kennedy. source 2, number 11 says \\\"In some vein, faithless electors have occasionally refused to vote for their party's candidate and cast a deciding vote for whoever they please...\\\" This means that with an Electoral college, the person you want to vote for may not even get picked cause of lying electors.\\n\\nEven though the electoral college is a pretty bad thing, there are still a few upsides. The Electoral college avoids te problem of neither candidates getting a majority of the votes. In source 3, number 22 There is no pressure for runoffelections when no candidatewins a a majority the votes cast that pressure, which would greatly complicate the presidential election process, is reduced by the electoral college, which invariable produces a clear winner... Simply this says that without the electoral college voting can be difficult and stressful.\\n\\nIn conclusion, The Electoral college may not be the best thing for our society, and also can we even trust that our votes even matter? either the Electoral college cant be trusted and it needs to be gone for good, or something needs to change.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"generated\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_train[\"prompt_id\"].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7fD4nZvN2a7",
        "outputId": "b37526fd-a0bc-4659-9c0e-090f46f7cb57"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_train[\"generated\"].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI9KzY32OJvJ",
        "outputId": "3199b438-7d49-4287-8972-98aedd8925bd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_train[\"text\"][0][:1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "HV75Xd-HOWD8",
        "outputId": "cb641033-cdb9-4a33-9211-71affe1c510b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Cars. Cars have been around since they became famous in the 1900s, when Henry Ford created and built the first ModelT. Cars have played a major role in our every day lives since then. But now, people are starting to question if limiting car usage would be a good thing. To me, limiting the use of cars might be a good thing to do.\\n\\nIn like matter of this, article, \"In German Suburb, Life Goes On Without Cars,\" by Elizabeth Rosenthal states, how automobiles are the linchpin of suburbs, where middle class families from either Shanghai or Chicago tend to make their homes. Experts say how this is a huge impediment to current efforts to reduce greenhouse gas emissions from tailpipe. Passenger cars are responsible for 12 percent of greenhouse gas emissions in Europe...and up to 50 percent in some carintensive areas in the United States. Cars are the main reason for the greenhouse gas emissions because of a lot of people driving them around all the time getting where they need to go. Article, \"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_test.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpREje12OnKd",
        "outputId": "4d751f33-5d41-474e-ea7e-856266d9f5b7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'prompt_id', 'text'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_prompt.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb4--gzvOwls",
        "outputId": "9c706e31-9787-433f-db14-5b22aefd5619"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['prompt_id', 'prompt_name', 'instructions', 'source_text'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_prompt.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "qr1ViKPgO2VV",
        "outputId": "d093dd61-efb9-40e4-fc69-751e59716841"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   prompt_id                       prompt_name  \\\n",
              "0          0                   Car-free cities   \n",
              "1          1  Does the electoral college work?   \n",
              "\n",
              "                                        instructions  \\\n",
              "0  Write an explanatory essay to inform fellow ci...   \n",
              "1  Write a letter to your state senator in which ...   \n",
              "\n",
              "                                         source_text  \n",
              "0  # In German Suburb, Life Goes On Without Cars ...  \n",
              "1  # What Is the Electoral College? by the Office...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54abd6ed-3c35-4356-81f8-d29af7babba1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>prompt_name</th>\n",
              "      <th>instructions</th>\n",
              "      <th>source_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Car-free cities</td>\n",
              "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
              "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Does the electoral college work?</td>\n",
              "      <td>Write a letter to your state senator in which ...</td>\n",
              "      <td># What Is the Electoral College? by the Office...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54abd6ed-3c35-4356-81f8-d29af7babba1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-54abd6ed-3c35-4356-81f8-d29af7babba1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-54abd6ed-3c35-4356-81f8-d29af7babba1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-72e0b5cc-89a1-4820-b060-7159b9a0ee80\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-72e0b5cc-89a1-4820-b060-7159b9a0ee80')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-72e0b5cc-89a1-4820-b060-7159b9a0ee80 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "src_prompt",
              "summary": "{\n  \"name\": \"src_prompt\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"prompt_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Does the electoral college work?\",\n          \"Car-free cities\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instructions\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Write a letter to your state senator in which you argue in favor of keeping the Electoral College or changing to election by popular vote for the president of the United States. Use the information from the texts in your essay. Manage your time carefully so that you can read the passages; plan your response; write your response; and revise and edit your response. Be sure to include a claim; address counterclaims; use evidence from multiple sources; and avoid overly relying on one source. Your response should be in the form of a multiparagraph essay. Write your response in the space provided.\",\n          \"Write an explanatory essay to inform fellow citizens about the advantages of limiting car usage. Your essay must be based on ideas and information that can be found in the passage set. Manage your time carefully so that you can read the passages; plan your response; write your response; and revise and edit your response. Be sure to use evidence from multiple sources; and avoid overly relying on one source. Your response should be in the form of a multiparagraph essay. Write your essay in the space provided.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"# What Is the Electoral College? by the Office of the Federal Register\\n\\n1 The Electoral College is a process, not a place. The founding fathers established it in the Constitution as a compromise between election of the President by a vote in Congress and election of the President by a popular vote of qualified citizens.\\n\\n2 The Electoral College process consists of the selection of the electors, the meeting of the electors where they vote for President and Vice President, and the counting of the electoral votes by Congress.\\n\\n3 The Electoral College consists of 538 electors. A majority of 270 electoral votes is required to elect the President. Your state\\u2019s entitled allotment of electors equals the number of members in its Congressional delegation: one for each member in the House of Representatives plus two for your Senators. . . .\\n\\n4 Under the 23rd Amendment of the Constitution, the District of Columbia is allocated 3 electors and treated like a state for purposes of the Electoral College. For this reason, in the following discussion, the word \\u201cstate\\u201d also refers to the District of Columbia.\\n\\n5 Each candidate running for President in your state has his or her own group of electors. The electors are generally chosen by the candidate\\u2019s political party, but state laws vary on how the electors are selected and what their responsibilities are. . . .\\n\\n6 The presidential election is held every four years on the Tuesday after the first Monday in November. You help choose your state\\u2019s electors when you vote for President because when you vote for your candidate you are actually voting for your candidate\\u2019s electors.\\n\\n7 Most states have a \\u201cwinner-take-all\\u201d system that awards all electors to the winning presidential candidate. However, Maine and Nebraska each have a variation of \\u201cproportional representation.\\u201d . . .\\n\\n8 After the presidential election, your governor prepares a \\u201cCertificate of Ascertainment\\u201d listing all of the candidates who ran for President in your state along with the names of their respective electors. The Certificate of Ascertainment also declares the winning presidential candidate in your state and shows which electors will represent your state at the meeting of the electors in December of the election year. Your state\\u2019s Certificates of Ascertainments are sent to the Congress and the National Archives as part of the official records of the presidential election.\\n\\n# The Indefensible Electoral College: Why even the best-laid defenses of the system are wrong by Bradford Plumer\\n\\n9 What have Richard Nixon, Jimmy Carter, Bob Dole, the U.S. Chamber of Commerce, and the AFL-CIO all, in their time, agreed on? Answer: Abolishing the electoral college! They\\u2019re not alone; according to a Gallup poll in 2000, taken shortly after Al Gore\\u2014thanks to the quirks of the electoral college\\u2014won the popular vote but lost the presidency,1 over 60 percent of voters would prefer a direct election to the kind we have now. This year voters can expect another close election in which the popular vote winner could again lose the presidency. And yet, the electoral college still has its defenders. What gives? . . . What\\u2019s wrong with the electoral college\\n\\n10 Under the electoral college system, voters vote not for the president, but for a slate of electors, who in turn elect the president. If you lived in Texas, for instance, and wanted to vote for John Kerry, you\\u2019d vote for a slate of 34 Democratic electors pledged to Kerry. On the offchance that those electors won the statewide election, they would go to Congress and Kerry would get 34 electoral votes. Who are the electors? They can be anyone not holding public office. Who picks the electors in the first place? It depends on the state. Sometimes state conventions, sometimes the state party\\u2019s central committee, sometimes the presidential candidates themselves. Can voters control whom their electors vote for? Not always. Do voters sometimes get confused about the electors and vote for the wrong candidate? Sometimes.\\n\\n11 The single best argument against the electoral college is what we might call the disaster factor. The American people should consider themselves lucky that the 2000 fiasco was the biggest election crisis in a century; the system allows for much worse. Consider that state legislatures are technically responsible for picking electors, and that those electors could always defy the will of the people. Back in 1960, segregationists in the Louisiana legislature nearly succeeded in replacing the Democratic electors with new electors who would oppose John F. Kennedy. (So that a popular vote for Kennedy would not have actually gone to Kennedy.) In the same vein, \\u201cfaithless\\u201d electors have occasionally refused to vote for their party\\u2019s candidate and cast a deciding vote for whomever they please. . . . Oh, and what if a state sends two slates of electors to Congress? It happened in Hawaii in 1960. Luckily, Vice President Richard Nixon, who was presiding over the Senate, validated only his opponent\\u2019s electors, but he made sure to do so \\u201cwithout establishing a precedent.\\u201d What if it happened again?\\n\\n12 Perhaps most worrying is the prospect of a tie in the electoral vote. In that case, the election would be thrown to the House of Representatives, where state delegations vote on the president. (The Senate would choose the vice-president.) Because each state casts only one vote, the single representative from Wyoming, representing 500,000 voters, would have as much say as the 55 representatives from California, who represent 35 million voters. Given that many voters vote one party for president and another for Congress, the House\\u2019s selection can hardly be expected to reflect the will of the people. And if an electoral tie seems unlikely, consider this: In 1968, a shift of just 41,971 votes would have deadlocked the election; In 1976, a tie would have occurred if a mere 5,559 voters in Ohio and 3,687 voters in Hawaii had voted the other way. The election is only a few swing voters away from catastrophe.\\n\\n13 At the most basic level, the electoral college is unfair to voters. Because of the winner-takeall system in each state, candidates don't spend time in states they know they have no chance of winning, focusing only on the tight races in the \\u201cswing\\u201d states. During the 2000 campaign, seventeen states didn\\u2019t see the candidates at all, including Rhode Island and South Carolina, and voters in 25 of the largest media markets didn\\u2019t get to see a single campaign ad. If anyone has a good argument for putting the fate of the presidency in the hands of a few swing voters in Ohio, they have yet to make it. . . .\\n\\n14 It\\u2019s official: The electoral college is unfair, outdated, and irrational. The best arguments in favor of it are mostly assertions without much basis in reality. And the arguments against direct elections are spurious at best. It\\u2019s hard to say this, but Bob Dole was right: Abolish the electoral college!\\n\\n# In Defense of the Electoral College: Five reasons to keep our despised method of choosing the President by Judge Richard A. Posner\\n\\n15 The Electoral College is widely regarded as an anachronism,1 a non-democratic method of selecting a president that ought to be overruled by declaring the candidate who receives the most popular votes the winner. The advocates of this position are correct in arguing that the Electoral College method is not democratic in a modern sense . . . it is the electors who elect the president, not the people. When you vote for a presidential candidate you\\u2019re actually voting for a slate of electors.\\n\\n16 But each party selects a slate of electors trusted to vote for the party\\u2019s nominee (and that trust is rarely betrayed) . . . however, it is entirely possible that the winner of the electoral vote will not win the national popular vote. Yet that has happened very rarely. It happened in 2000, when Gore had more popular votes than Bush yet fewer electoral votes, but that was the first time since 1888.\\n\\n17 There are five reasons for retaining the Electoral College despite its lack of democratic pedigree;2 all are practical reasons, not liberal or conservative3 reasons.\\n\\n## 1) Certainty of Outcome\\n\\n18 A dispute over the outcome of an Electoral College vote is possible\\u2014--it happened in 2000--\\u2014but it\\u2019s less likely than a dispute over the popular vote. The reason is that the winning candidate\\u2019s share of the Electoral College invariably exceeds his share of the popular vote. In 2012\\u2019s election, for example, Obama4 received 61.7 percent of the electoral vote compared to only 51.3 percent of the popular votes cast for him and Romney.5 . . . Because almost all states award electoral votes on a winner-take-all basis, even a very slight plurality6 in a state creates a landslide electoral-vote victory in that state. A tie in the nationwide electoral vote is possible because the total number of votes\\u2014--538\\u2014--is an even number, but it is highly unlikely. . . .\\n\\n## 2) Everyone\\u2019s President\\n\\n19 The Electoral College requires a presidential candidate to have trans-regional appeal. No region (South, Northeast, etc.) has enough electoral votes to elect a president. So a solid regional favorite, such as Romney was in the South, has no incentive to campaign heavily in those states, for he gains no electoral votes by increasing his plurality in states that he knows he will win. This is a desirable result because a candidate with only regional appeal is unlikely to be a successful president. The residents of the other regions are likely to feel disenfranchised\\u2014to feel that their votes do not count, that the new president will have no regard for their interests, that he really isn\\u2019t their president.\\n\\n## 3) Swing States\\n\\n20 The winner-take-all method of awarding electoral votes induces the candidates\\u2014as we saw in 2012\\u2019s election\\u2014to focus their campaign efforts on the toss-up states . . . . Voters in toss-up states are more likely to pay close attention to the campaign\\u2014to really listen to the competing candidates\\u2014knowing that they are going to decide the election. They are likely to be the most thoughtful voters, on average (and for the further reason that they will have received the most information and attention from the candidates), and the most thoughtful voters should be the ones to decide the election.\\n\\n## 4) Big States\\n\\n21 The Electoral College restores some of the weight in the political balance that large states (by population) lose by virtue of the mal-apportionment of the Senate decreed in the Constitution. . . . The popular vote was very close in Florida in 2012; nevertheless Obama, who won that vote, got 29 electoral votes. A victory by the same margin in Wyoming would net the winner only 3 electoral votes. So, other things being equal, a large state gets more attention from presidential candidates in a campaign than a small state does. . . .\\n\\n## 5) Avoid Run-Off Elections\\n\\n22 The Electoral College avoids the problem of elections in which no candidate receives a majority of the votes cast. For example, Nixon in 1968 and Clinton in 1992 both had only a 43 percent plurality of the popular votes, while winning a majority in the Electoral College (301 and 370 electoral votes, respectively). There is pressure for run-off elections when no candidate wins a majority of the votes cast; that pressure, which would greatly complicate the presidential election process, is reduced by the Electoral College, which invariably produces a clear winner. . . .\\n\\n23 It can be argued that the Electoral College method of selecting the president may turn off potential voters for a candidate who has no hope of carrying their state\\u2014Democrats in Texas, for example, or Republicans in California. Knowing their vote will have no effect, they have less incentive to pay attention to the campaign than they would have if the president were picked by popular vote . . . . But of course no voter\\u2019s vote swings a national election, and in spite of that, about one-half the eligible American population did vote in 2012\\u2019s election. Voters in presidential elections are people who want to express a political preference rather than people who think that a single vote may decide an election. . . .\\n\",\n          \"# In German Suburb, Life Goes On Without Cars by Elisabeth Rosenthal\\n\\n1 VAUBAN, Germany\\u2014Residents of this upscale community are suburban pioneers, going where few soccer moms or commuting executives have ever gone before: they have given up their cars.\\n\\n2 Street parking, driveways and home garages are generally forbidden in this experimental new district on the outskirts of Freiburg, near the French and Swiss borders. Vauban\\u2019s streets are completely \\u201ccar-free\\u201d\\u2014except the main thoroughfare, where the tram to downtown Freiburg runs, and a few streets on one edge of the community. Car ownership is allowed, but there are only two places to park\\u2014large garages at the edge of the development, where a car-owner buys a space, for $40,000, along with a home.\\n\\n3 As a result, 70 percent of Vauban\\u2019s families do not own cars, and 57 percent sold a car to move here. \\u201cWhen I had a car I was always tense. I\\u2019m much happier this way,\\u201d said Heidrun Walter, a media trainer and mother of two, as she walked verdant streets where the swish of bicycles and the chatter of wandering children drown out the occasional distant motor.\\n\\n4 Vauban, completed in 2006, is an example of a growing trend in Europe, the United States and elsewhere to separate suburban life from auto use, as a component of a movement called \\u201csmart planning.\\u201d\\n\\n5 Automobiles are the linchpin of suburbs, where middle-class families from Chicago to Shanghai tend to make their homes. And that, experts say, is a huge impediment to current efforts to drastically reduce greenhouse gas emissions from tailpipes . . . . Passenger cars are responsible for 12 percent of greenhouse gas emissions in Europe . . . and up to 50 percent in some car-intensive areas in the United States.\\n\\n6 While there have been efforts in the past two decades to make cities denser, and better for walking, planners are now taking the concept to the suburbs . . . . Vauban, home to 5,500 residents within a rectangular square mile, may be the most advanced experiment in low-car suburban life. But its basic precepts are being adopted around the world in attempts to make suburbs more compact and more accessible to public transportation, with less space for parking. In this new approach, stores are placed a walk away, on a main street, rather than in malls along some distant highway.\\n\\n7 \\u201cAll of our development since World War II has been centered on the car, and that will have to change,\\u201d said David Goldberg, an official of Transportation for America, a fast-growing coalition of hundreds of groups in the United States . . . who are promoting new communities that are less dependent on cars. Mr. Goldberg added: \\u201cHow much you drive is as important as whether you have a hybrid.\\u201d\\n\\n8 Levittown and Scarsdale, New York suburbs with spread-out homes and private garages, were the dream towns of the 1950s and still exert a strong appeal. But some new suburbs may well look more Vauban-like, not only in developed countries but also in the developing world, where emissions from an increasing number of private cars owned by the burgeoning middle class are choking cities.\\n\\n9 In the United States, the Environmental Protection Agency is promoting \\u201ccar reduced\\u201d communities, and legislators are starting to act, if cautiously. Many experts expect public transport serving suburbs to play a much larger role in a new six-year federal transportation bill to be approved this year, Mr. Goldberg said. In previous bills, 80 percent of appropriations have by law gone to highways and only 20 percent to other transport. \\n\\nExcerpt from \\u201cIn German Suburb, Life Goes On Without Cars\\u201d by Elisabeth Rosenthal, from the New York Times. Copyright \\u00a9 2009 by the New York Times Company. Reprinted by permission of the New York Times Company via Copyright Clearance Center.\\n\\n# Paris bans driving due to smog by Robert Duffer\\n\\n10 After days of near-record pollution, Paris enforced a partial driving ban to clear the air of the global city.\\n\\n11 On Monday motorists with even-numbered license plates were ordered to leave their cars at home or suffer a 22-euro fine ($31). The same would apply to odd-numbered plates the following day.\\n\\n12 Almost 4,000 drivers were fined, according to Reuters1 . . . [Twenty-seven] people had their cars impounded for their reaction to the fine.\\n\\n13 That\\u2019s easier to imagine than a car-free Champs-Elysees.2\\n\\n14 Congestion 3 was down 60 percent in the capital of France, after five-days of intensifying smog . . . [The smog] rivaled Beijing, China, which is known as one of the most polluted cities in the world.\\n\\n15 Cold nights and warm days caused the warmer layer of air to trap car emissions.\\n\\n16 Diesel fuel was blamed, since France has . . . [a] tax policy that favors diesel over gasoline. Diesels make up 67 percent of vehicles in France, compared to a 53.3 percent average of diesel engines in the rest of Western Europe, according to Reuters.\\n\\n17 Paris typically has more smog than other European capitals . . . [Last] week Paris had 147 micrograms of particulate matter (PM) per cubic meter compared with 114 in Brussels and 79.7 in London, Reuters found.\\n\\n18 Delivery companies complained of lost revenue, while exceptions were made for plug-in cars, hybrids, and cars carrying three or more passengers. Public transit was free of charge from Friday to Monday, according to the BBC.\\n\\n19 The smog cleared enough Monday for the ruling French party to rescind the ban for oddnumbered plates on Tuesday. 1\\n\\nExcerpt from \\u201cParis bans driving due to smog\\u201d by Robert Duffer, from the Chicago Tribune. Copyright \\u00a9 2014 by the Chicago Tribune. Reprinted by permission of the Chicago Tribune via Copyright Clearance Center.\\n\\n# Car-free day is spinning into a big hit in Bogota by Andrew Selsky\\n\\nBOGOTA, Colombia\\u2014In a program that\\u2019s set to spread to other countries, millions of Colombians hiked, biked, skated or took buses to work during a car-free day yesterday, leaving the streets of this capital city eerily devoid of traffic jams.\\n\\n21 It was the third straight year cars have been banned with only buses and taxis permitted for the Day Without Cars in this capital city of 7 million. The goal is to promote alternative transportation and reduce smog. Violators faced $25 fines.\\n\\n22 The turnout was large, despite gray clouds that dumped occasional rain showers on Bogota.\\n\\n23 \\u201cThe rain hasn\\u2019t stopped people from participating,\\u201d said Bogota Mayor Antanas Mockus . . . .\\n\\n24 \\u201cIt\\u2019s a good opportunity to take away stress and lower air pollution,\\u201d said businessman Carlos Arturo Plaza as he rode a two-seat bicycle with his wife.\\n\\n25 For the first time, two other Colombian cities, Cali and Valledupar, joined the event.\\n\\n26 Municipal authorities from other countries came to Bogota to see the event and were enthusiastic. \\u201cThese people are generating a revolutionary change, and this is crossing borders,\\u201d said Enrique Riera, the mayor of Asunci\\u00f3n, Paraguay. . . .\\n\\n27 The day without cars is part of an improvement campaign that began in Bogota in the mid1990s. It has seen the construction of 118 miles of bicycle paths, the most of any Latin American city, according to Mockus, the city\\u2019s mayor.\\n\\n28 Parks and sports centers also have bloomed throughout the city; uneven, pitted sidewalks have been replaced by broad, smooth sidewalks; rush-hour restrictions have dramatically cut traffic; and new restaurants and upscale shopping districts have cropped up.\\n\\nExcerpt from \\u201cCar-free day is spinning into a big hit in Bogota\\u201d by Andrew Selsky, from the Seattle Times. Copyright \\u00a9 2002 by the Seattle Times Company. Reprinted by permission of the Seattle Times Company via Copyright Clearance Center.\\n\\n# The End of Car Culture by Elisabeth Rosenthal\\n\\n29 President Obama\\u2019s ambitious goals to curb the United States\\u2019 greenhouse gas emissions, unveiled last week, will get a fortuitous assist from an incipient1 shift in American behavior: recent studies suggest that Americans are buying fewer cars, driving less and getting fewer licenses as each year goes by.\\n\\n30 That has left researchers pondering a fundamental question: Has America passed peak driving?\\n\\n31 The United States, with its broad expanses and suburban ideals, had long been one of the world\\u2019s prime car cultures. It is the birthplace of the Model T; the home of Detroit; the place where Wilson Pickett immortalized \\u201cMustang Sally\\u201d . . . .\\n\\n32 But America\\u2019s love affair with its vehicles seems to be cooling. When adjusted for population growth, the number of miles driven in the United States peaked in 2005 and dropped steadily thereafter, according to an analysis by Doug Short of Advisor Perspectives, an investment research company. As of April 2013, the number of miles driven per person was nearly 9 percent below the peak and equal to where the country was in January 1995. Part of the explanation certainly lies in the recession, because cash-strapped Americans could not afford new cars, and the unemployed weren\\u2019t going to work anyway. But by many measures the decrease in driving preceded the downturn and appears to be persisting now that recovery is under way. The next few years will be telling.\\n\\n33 \\u201cWhat most intrigues me is that rates of car ownership per household and per person started to come down two to three years before the downturn,\\u201d said Michael Sivak, who studies the trend and who is a research professor at the University of Michigan\\u2019s Transportation Research Institute. \\u201cI think that means something more fundamental is going on.\\u201d\\n\\n34 If the pattern persists\\u2014and many sociologists believe it will\\u2014it will have beneficial implications for carbon emissions and the environment, since transportation is the second largest source of America\\u2019s emissions, just behind power plants. But it could have negative implications for the car industry. Indeed, companies like Ford and Mercedes are already rebranding themselves \\u201cmobility\\u201d companies with a broader product range beyond the personal vehicle.\\n\\n35 \\u201cDifferent things are converging which suggest that we are witnessing a long-term cultural shift,\\u201d said Mimi Sheller, a sociology professor at Drexel University and director of its Mobilities Research and Policy Center. She cites various factors: the Internet makes telecommuting possible and allows people to feel more connected without driving to meet friends. The renewal of center cities has made the suburbs less appealing and has drawn empty nesters back in. Likewise the rise in cellphones and car-pooling apps has facilitated more flexible commuting arrangements, including the evolution of shared van services for getting to work.\\n\\n36 With all these changes, people who stopped car commuting as a result of the recession may find less reason to resume the habit. . . .\\n\\n37 New York\\u2019s new bike-sharing program and its skyrocketing bridge and tunnel tolls reflect those new priorities, as do a proliferation of car-sharing programs across the nation.\\n\\n38 Demographic shifts in the driving population suggest that the trend may accelerate. There has been a large drop in the percentage of 16- to 39-year-olds getting a license, while older people are likely to retain their licenses as they age, Mr. Sivak\\u2019s research has found.\\n\\n39 He and I have similar observations about our children. Mine (19 and 21) have not bothered to get a driver\\u2019s license, even though they both live in places where one could come in handy. They are interested, but it\\u2019s not a priority. They organize their summer jobs and social life around where they can walk or take public transportation or car-pool with friends.\\n\\n40 Mr. Sivak\\u2019s son lives in San Francisco and has a car but takes Bay Area Rapid Transit, when he can, even though that often takes longer than driving. \\u201cWhen I was in my 20s and 30s,\\u201d Mr. Sivak said, \\u201cI was curious about what kind of car people drove, but young people don\\u2019t really care. A car is just a means of getting from A to B when BART doesn\\u2019t work.\\u201d\\n\\n41 A study last year found that driving by young people decreased 23 percent between 2001 and 2009. . . .\\n\\n42 Whether members of the millennial generation will start buying more cars once they have kids to take to soccer practice and school plays remains an open question. But such projections have important business implications, even if car buyers are merely older or buying fewer cars in a lifetime rather than rejecting car culture outright.\\n\\n43 At the Mobile World Congress last year in Barcelona, Spain, Bill Ford, executive chairman of the Ford Motor Company, laid out a business plan for a world in which personal vehicle ownership is impractical or undesirable. He proposed partnering with the telecommunications industry to create cities in which \\u201cpedestrian, bicycle, private cars, commercial and public transportation traffic are woven into a connected network to save time, conserve resources, lower emissions and improve safety.\\u201d\\n\\nExcerpt from \\u201cThe End of Car Culture\\u201d by Elisabeth Rosenthal, from the New York Times. Copyright \\u00a9 2013 by the New York Times Company. Reprinted by permission of the New York Times Company via Copyright Clearance Center.\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📊 Quick Statistical Overview\n",
        "\n",
        "Before building our model, let's explore the training data to understand its structure:\n",
        "\n",
        "- We check the **class distribution** in the `generated` column to see if the dataset is balanced.\n",
        "- We compute the **average length** of the texts, which may influence model performance or input preprocessing.\n",
        "- We also compare the number of **unique prompts** with the number of **prompt references** in the training set, to see how the essays are distributed across prompts.\n",
        "\n",
        "This gives us a quick but useful overview of our data before diving into modeling.\n"
      ],
      "metadata": {
        "id": "CI0FfzStbYUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick statiscal anlysis\n",
        "print(\"\\n Distribution des classes (colonne 'generated') :\")\n",
        "print(src_train['generated'].value_counts())\n",
        "\n",
        "print(\"\\n Longueur moyenne des textes :\")\n",
        "src_train['text_length'] = src_train['text'].apply(len)\n",
        "print(src_train['text_length'].describe())\n",
        "\n",
        "print(\"\\n Nombre de prompts uniques :\", src_prompt['prompt_id'].nunique())\n",
        "print(\" Nombre de correspondances entre prompts et essais :\", src_train['prompt_id'].nunique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsLU9qDKPYPm",
        "outputId": "4fe295ee-3355-40d2-91dc-82ae9c1cdd8b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Distribution des classes (colonne 'generated') :\n",
            "generated\n",
            "0    1375\n",
            "1       3\n",
            "Name: count, dtype: int64\n",
            "\n",
            " Longueur moyenne des textes :\n",
            "count    1378.000000\n",
            "mean     3169.050798\n",
            "std       920.588198\n",
            "min      1356.000000\n",
            "25%      2554.250000\n",
            "50%      2985.500000\n",
            "75%      3623.750000\n",
            "max      8436.000000\n",
            "Name: text_length, dtype: float64\n",
            "\n",
            " Nombre de prompts uniques : 2\n",
            " Nombre de correspondances entre prompts et essais : 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing the BERT Model for Embeddings\n",
        "\n",
        "In this step, we load a pre-trained BERT model (`bert-base-uncased`) from Hugging Face Transformers.\n",
        "\n",
        "Here's what we do:\n",
        "- Load the **BERT tokenizer** to preprocess text into tokens compatible with the model.\n",
        "- Load the **full classification model**, which includes the encoder (BERT) and a classification head.\n",
        "- **Extract only the encoder part** (i.e., the base BERT layers without the classification head), which we'll use to generate text embeddings.\n",
        "\n",
        "These embeddings will later be used as input to the **GAN discriminator**, which learns to distinguish between human-written and AI-generated text.\n"
      ],
      "metadata": {
        "id": "DU0P4D4xblkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the BERT model for embeddings\n",
        "\n",
        "tokenizer_save_path = \"bert_tokenizer\"\n",
        "model_save_path = \"bert_model\"\n",
        "\n",
        "# Load the pre-trained BERT tokenizer (lowercased version)\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Load the full BERT model for sequence classification\n",
        "# We'll use this for the discriminator later\n",
        "pretrained_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Extract only the encoder (embedding layers), without the classification head\n",
        "embedding_model = pretrained_model.bert\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336,
          "referenced_widgets": [
            "20d9816968644e6b87ab3229fb51df84",
            "85884b295b2d45b794c975bd39a0dfbd",
            "a7fa897f7b0748b6b22c6a5d2d3f4fe0",
            "3cde6f407c434c689707bd741c7f4c18",
            "e34375ed0c3c4645812bf52f427ced77",
            "e077762635ec442e8cb8b992ade9e2f3",
            "85a8eb2bbdef4aceb7c3fae0fb609351",
            "db0088220b124d109e8a5655e59801fb",
            "83698769d7224238b5b21c857e1b7296",
            "3740902629f04d44bb50877a2d0ac757",
            "0ea33261a9d540bca5f2d067d621d8c6",
            "764cb9101d934cb892331e9462ae706c",
            "c5c8d15e3035406a8a50ef0a417a35ed",
            "46315c2d6d2d4cfb8cbac5d8ab876629",
            "83e7f82db6c1495c853205e286a0ffb4",
            "97a1b62ca1d5431abfe48edb7c60df1e",
            "f8068a85963a45b58fb54251c97d5b52",
            "3d84a3b4120b4d58a3b4b3aebaa83e51",
            "1948fd2ed860412faf82f092956c8988",
            "4231d33a153c4a9f89dab00243d33317",
            "9eea0c865b72428cb07a6df158f1767f",
            "8624e7569dbc452a9ed6e98443844122",
            "15fbce8a17a74fac8cf1e04a8f581349",
            "f1c89ea7413646fbbf65537669f898a8",
            "87d0824fa766486fbb53a0b20c1f8639",
            "41dc3e98c02c4564b7ce7f3d6b12d26c",
            "c070073fc44840b68fafb36e1c7a01ff",
            "d47c0ae4f83a42228ac04bd948a15f77",
            "c7b50ae81b8e4e8b95626f4f2ffc1bcb",
            "c8e31c7ca73f426e82984c7c7f702642",
            "22434dd4e1d543d48c37482fd5f5a9de",
            "486d37a86447429080ac1e3eb6ea7237",
            "e73283604bb042819f39ffd69aee65bc",
            "2edd2acaf2c14b0580057a3509bffe5a",
            "73b46bb3ccdf4649be3fd00c22e7b1c7",
            "3fdb37518ecb4862bfd1836fd6802da3",
            "51c842674aaf4c23ad6dce997b4b7b37",
            "50d1443eff334257a9093411110324d9",
            "84173d0e52c64ab3af3b53bafc813d2a",
            "36441753c3b746cb9394b9078f8bc83a",
            "03339e2543374788bb82c1d6adb2c2f3",
            "ed75c20d30e948a8a653ee260d30c983",
            "89c08d889cff405f8dae31f3d921037d",
            "4bbd6332bd8a4ab1a02fe6331ff54889",
            "4a4562ea2d84443c9ae6a8743c73b822",
            "4ec08f4eed3b4e2c9d7aafda2617639d",
            "cbd4b29338ad46278d78855c6becfdd2",
            "9c3daaeff870470ea69c878c241ad7ff",
            "a77442671a544803a3ab588853aee499",
            "0d1f1f2135ca4cc5b57a950de6262064",
            "81ac7331c9b84c85a086012979dfb3e1",
            "2571a2577fb5473d904bf4319f734259",
            "050d3e0cb38e46a0ab86b6c43d1e261e",
            "3b575db704c246b0bcea606c90b8e664",
            "385e400a7cce49f6bdd68a1786f75b14"
          ]
        },
        "id": "K_XHnNnKeoGm",
        "outputId": "3935a3f4-23c3-4179-ddeb-f6e36bbd26d6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20d9816968644e6b87ab3229fb51df84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "764cb9101d934cb892331e9462ae706c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15fbce8a17a74fac8cf1e04a8f581349"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2edd2acaf2c14b0580057a3509bffe5a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a4562ea2d84443c9ae6a8743c73b822"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example batch of texts (you can later apply this to the full dataset)\n",
        "sample_texts = src_train['text'].tolist()[:4]  # Take a few samples for now\n",
        "\n",
        "# Tokenization: converts text into input_ids and attention masks\n",
        "inputs = tokenizer(sample_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# Extract embeddings from BERT (encoder only, no classification head)\n",
        "with torch.no_grad():\n",
        "    outputs = embedding_model(**inputs)\n",
        "\n",
        "# outputs.last_hidden_state → (batch_size, sequence_length, hidden_dim)\n",
        "# We'll use the [CLS] token representation as a global summary of each input\n",
        "embeddings = outputs.last_hidden_state[:, 0, :]  # shape = (batch_size, hidden_dim)\n",
        "\n",
        "print(\"Shape of extracted embeddings:\", embeddings.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyPHS1whTEYg",
        "outputId": "e85d6054-80c9-4c9e-8fea-898dfd548eef"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of extracted embeddings: torch.Size([4, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all texts in the training dataset\n",
        "inputs = tokenizer(\n",
        "    src_train[\"text\"].tolist(),\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    max_length=512,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "# Run the inputs through BERT encoder (without classification head)\n",
        "embedding_model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = embedding_model(**inputs)\n",
        "    # Extract the [CLS] token embeddings (represents the entire input)\n",
        "    text_embeddings = outputs.last_hidden_state[:, 0, :]  # shape = (batch_size, hidden_dim)\n",
        "\n",
        "print(\"Extracted embeddings shape:\", text_embeddings.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9FdXmQSaFjh",
        "outputId": "1c122907-bd74-4a64-c62e-2e347d953d6b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted embeddings shape: torch.Size([1378, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# Parameter definition\"\"\"\n",
        "\n",
        "train_batch_size = 32         # Reasonable batch size for BERT fine-tuning\n",
        "test_batch_size = 64          # Larger batch size for inference (no backpropagation)\n",
        "lr = 2e-5                     # Learning rate commonly used for BERT and GANs\n",
        "beta1 = 0.5                   # Beta1 parameter for Adam optimizer, standard for GAN training\n",
        "nz = 100                      # Dimensionality of the latent vector (input to the generator)\n",
        "num_epochs = 5                # Number of training epochs (adjustable based on time and overfitting)\n",
        "num_hidden_layers = 2         # Number of hidden layers for both the generator and discriminator\n",
        "train_ratio = 1               # One discriminator step per generator_\n"
      ],
      "metadata": {
        "id": "vQ0-8vSGepE2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# Data Preparation\"\"\"\n",
        "\n",
        "# Custom PyTorch Dataset to wrap our embeddings and labels\n",
        "class GANDAIGDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.texts = texts            # Could be embeddings in this case\n",
        "        self.labels = labels          # Corresponding binary labels (0 = human, 1 = AI)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)        # Returns the total number of examples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.texts[idx], self.labels[idx]  # Fetch one (embedding, label) pair\n",
        "\n",
        "# Total number of training examples\n",
        "all_num = len(src_train)\n",
        "\n",
        "# Ratio used to split the dataset into training and testing\n",
        "train_ratio_split = 0.8\n",
        "train_num = int(all_num * train_ratio_split)   # Number of training examples\n",
        "test_num = all_num - train_num                 # Remaining go to test set\n",
        "\n",
        "# Split the embeddings and labels accordingly\n",
        "train_embeddings = text_embeddings[:train_num]     # Training embeddings\n",
        "test_embeddings = text_embeddings[train_num:]      # Testing embeddings\n",
        "\n",
        "train_labels = src_train['generated'].values[:train_num]   # Training labels\n",
        "test_labels = src_train['generated'].values[train_num:]    # Testing labels\n",
        "\n",
        "# Store the original dataframes for inspection or future use\n",
        "train_set = src_train.iloc[:train_num]\n",
        "test_set = pd.concat([\n",
        "    src_train.iloc[train_num:],\n",
        "]).reset_index(drop=True)\n",
        "\n",
        "# Create custom datasets for PyTorch\n",
        "train_dataset = GANDAIGDataset(train_embeddings, train_labels)\n",
        "test_dataset = GANDAIGDataset(test_embeddings, test_labels)\n",
        "\n",
        "# Wrap the datasets in DataLoaders for batch training\n",
        "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "kztjJrs3fUmV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# Generator definition\"\"\"\n",
        "\n",
        "# Define a BERT-style encoder configuration to reuse for the simulated embedding layer\n",
        "config = BertConfig(num_hidden_layers=num_hidden_layers)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        # Project the latent noise vector z into an intermediate shape suitable for transposed convolutions\n",
        "        self.fc = nn.Linear(input_dim, 256 * 4)  # Output shape: (batch, 1024)\n",
        "\n",
        "        # Transposed convolutional layers to simulate a temporal-like sequence that will resemble a BERT embedding\n",
        "        self.conv_net = nn.Sequential(\n",
        "            nn.ConvTranspose1d(256, 128, kernel_size=4, stride=2),  # Output: (batch, 128, 10)\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose1d(128, 64, kernel_size=4, stride=2),   # Output: (batch, 64, 22)\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose1d(64, 32, kernel_size=4, stride=2),    # Output: (batch, 32, ~46)\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose1d(32, 1, kernel_size=4, stride=2),     # Output: (batch, 1, ~96)\n",
        "            nn.AdaptiveAvgPool1d(96),  # Ensures fixed-length output (batch, 1, 96)\n",
        "            nn.Flatten(),              # Flatten to (batch, 96)\n",
        "            nn.Linear(96, 768)         # Final projection to match BERT embedding size\n",
        "        )\n",
        "\n",
        "        # Optional: add a BERT encoder block to refine the output embedding\n",
        "        self.bert_encoder = BertEncoder(config)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)                        # (batch, 1024)\n",
        "        x = x.view(-1, 256, 4)                # Reshape to (batch, channels, seq_len)\n",
        "        x = self.conv_net(x)                  # (batch, 768)\n",
        "\n",
        "        # Simulate a [CLS]-like embedding for compatibility with discriminator\n",
        "        extended = x.unsqueeze(1)             # Add sequence dimension: (batch, 1, 768)\n",
        "\n",
        "        # Create an attention mask (all ones, since we only have one token)\n",
        "        attention_mask = torch.ones((x.size(0), 1), dtype=torch.long, device=x.device)\n",
        "\n",
        "        # Pass through a BERT encoder layer for refinement\n",
        "        encoder_outputs = self.bert_encoder(\n",
        "            hidden_states=extended,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "\n",
        "        # Extract the output embedding (like [CLS] token)\n",
        "        x = encoder_outputs.last_hidden_state[:, 0, :]  # Final shape: (batch, 768)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "KUIlF2KGeeux"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# Discriminator definition\"\"\"\n",
        "\n",
        "from transformers import BertModel\n",
        "\n",
        "# Custom pooling layer: performs sum pooling over token embeddings\n",
        "class SumBertPooler(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
        "        # Sum all token embeddings along the sequence dimension\n",
        "        sum_hidden = hidden_states.sum(dim=1)  # Shape: (batch_size, hidden_dim)\n",
        "\n",
        "        # Compute the number of non-zero tokens per sequence (to normalize)\n",
        "        sum_mask = sum_hidden.sum(1).unsqueeze(1)  # Shape: (batch_size, 1)\n",
        "\n",
        "        # Clamp values to avoid division by zero\n",
        "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
        "\n",
        "        # Compute average embedding for each sequence\n",
        "        mean_embeddings = sum_hidden / sum_mask  # Final shape: (batch_size, hidden_dim)\n",
        "        return mean_embeddings\n"
      ],
      "metadata": {
        "id": "76PSssGmenly"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminator network for GAN — takes a BERT-like embedding as input\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Simple feedforward classifier:\n",
        "        # Input: BERT embedding (size 768)\n",
        "        # Output: probability of being AI-generated (scalar between 0 and 1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(768, 256),  # Reduce dimensionality\n",
        "            nn.ReLU(),            # Activation function\n",
        "            nn.Linear(256, 1),    # Output one logit\n",
        "            nn.Sigmoid()          # Convert logit to probability (0 = human, 1 = AI)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):  # x: tensor of shape (batch_size, 768)\n",
        "        return self.classifier(x)\n"
      ],
      "metadata": {
        "id": "HbSquB_uezco"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate the discriminator using AUC score\n",
        "def eval_auc(model):\n",
        "    model.eval()  # Set the model to evaluation mode (no dropout, etc.)\n",
        "\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation for inference\n",
        "        for batch in test_loader:\n",
        "            embeddings = batch[0].to(device)       # Input embeddings (from BERT or generator)\n",
        "            labels = batch[1].float().to(device)   # Ground truth labels (0 = human, 1 = AI)\n",
        "\n",
        "            outputs = model(embeddings).squeeze()  # Model outputs: predicted probabilities\n",
        "            predictions.extend(outputs.cpu().numpy())  # Collect predictions\n",
        "            actuals.extend(labels.cpu().numpy())       # Collect true labels\n",
        "\n",
        "    # Compute AUC score (Area Under the ROC Curve)\n",
        "    auc = roc_auc_score(actuals, predictions)\n",
        "    print(\"AUC:\", round(auc, 4))\n",
        "    return auc\n"
      ],
      "metadata": {
        "id": "B2XbsNKCfbAu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model state and metadata for tracking or checkpointing\n",
        "def get_model_info_dict(model, epoch, auc_score):\n",
        "    # Store current device to restore the model later\n",
        "    current_device = next(model.parameters()).device\n",
        "\n",
        "    # Move model to CPU temporarily for saving (device agnostic)\n",
        "    model.to('cpu')\n",
        "\n",
        "    # Create a dictionary with model state and metadata\n",
        "    model_info = {\n",
        "        'epoch': epoch,                        # Current training epoch\n",
        "        'model_state_dict': model.state_dict(),# Model weights\n",
        "        'auc_score': auc_score                 # AUC score at the time of saving\n",
        "    }\n",
        "\n",
        "    # Move model back to its original device\n",
        "    model.to(current_device)\n",
        "\n",
        "    return model_info\n"
      ],
      "metadata": {
        "id": "f6lYifrTglb2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to prepare BERT embeddings from raw text input\n",
        "def preparation_embedding(texts):\n",
        "    # Tokenize input texts (pad and truncate to max length)\n",
        "    encodings = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    # Extract tokenized input components\n",
        "    input_ids = encodings['input_ids']\n",
        "    token_type_ids = encodings['token_type_ids']\n",
        "\n",
        "    # Generate embeddings using the BERT encoder\n",
        "    embeded = embedding_model(input_ids=input_ids, token_type_ids=token_type_ids)\n",
        "\n",
        "    return embeded  # Returns the full output, including last_hidden_state\n"
      ],
      "metadata": {
        "id": "LYFIHhN3gpks"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One training step for both the Generator and Discriminator in the GAN\n",
        "def GAN_step(optimizerG, optimizerD, netG, netD, real_data, label, epoch, i):\n",
        "    netD.zero_grad()  # Reset gradients for the discriminator\n",
        "    batch_size = real_data.size(0)\n",
        "\n",
        "    # Ensure the labels are in the correct shape (batch_size, 1)\n",
        "    label = label.view(-1, 1)\n",
        "\n",
        "    # === Step 1: Discriminator on Real Data ===\n",
        "    output = netD(real_data)                     # Forward pass with real data\n",
        "    errD_real = criterion(output, label)         # Binary cross-entropy loss on real labels (should be 1)\n",
        "    errD_real.backward()                         # Backpropagate the error\n",
        "    D_x = output.mean().item()                   # Average prediction on real data (closer to 1 is better)\n",
        "\n",
        "    # === Step 2: Discriminator on Fake Data ===\n",
        "    noise = torch.randn(batch_size, nz, device=device)     # Generate random noise vectors\n",
        "    fake_data = netG(noise)                                # Generate fake embeddings\n",
        "    label_fake = torch.zeros(batch_size, 1, device=device) # Fake labels = 0\n",
        "\n",
        "    output = netD(fake_data.detach())           # Detach fake data to avoid updating generator yet\n",
        "    errD_fake = criterion(output, label_fake)   # Loss on fake predictions\n",
        "    errD_fake.backward()                        # Backpropagate the fake error\n",
        "    D_G_z1 = output.mean().item()               # Average discriminator output on fake data\n",
        "\n",
        "    errD = errD_real + errD_fake                # Total discriminator loss\n",
        "    optimizerD.step()                           # Update discriminator weights\n",
        "\n",
        "    # === Step 3: Generator Tries to Fool the Discriminator ===\n",
        "    netG.zero_grad()                                           # Reset generator gradients\n",
        "    label_real_for_G = torch.ones(batch_size, 1, device=device)  # Generator wants output to be classified as real (1)\n",
        "    output = netD(fake_data)                                   # Forward fake data again (this time, keep gradients)\n",
        "    errG = criterion(output, label_real_for_G)                 # Generator loss (wants D(fake) close to 1)\n",
        "    errG.backward()                                            # Backpropagate generator loss\n",
        "    D_G_z2 = output.mean().item()                              # Average D output after generator update\n",
        "    optimizerG.step()                                          # Update generator weights\n",
        "\n",
        "    # Optional logging\n",
        "    if i % 50 == 0:\n",
        "        print('[%d/%d][%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
        "              % (epoch, num_epochs, i, errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "\n",
        "    return optimizerG, optimizerD, netG, netD\n"
      ],
      "metadata": {
        "id": "_5JWPSTlnx29"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Model Initialization ---\n",
        "\n",
        "# Instantiate the Generator and Discriminator models and move them to the correct device (CPU or GPU)\n",
        "netG = Generator(nz).to(device)  # Generator takes latent vector of size nz\n",
        "netD = Discriminator().to(device)  # Discriminator takes BERT-style embeddings\n",
        "\n",
        "# Define the loss function for both networks (Binary Cross Entropy)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Define optimizers for both networks using Adam\n",
        "# Standard GAN beta values: beta1 = 0.5, beta2 = 0.999\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n"
      ],
      "metadata": {
        "id": "rdeAtlpfg0XC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Training Loop ---\n",
        "\n",
        "model_infos = []  # Store model info (state, epoch, AUC) at each epoch\n",
        "\n",
        "# Loop over the number of training epochs\n",
        "for epoch in range(num_epochs):\n",
        "    # Iterate over the training DataLoader\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # Get the real data embeddings and move them to the appropriate device\n",
        "        with torch.no_grad():\n",
        "            embeded = data[0].to(device)  # Real BERT embeddings (detached from graph)\n",
        "\n",
        "        # Perform one GAN training step (D + G update)\n",
        "        optimizerG, optimizerD, netG, netD = GAN_step(\n",
        "            optimizerG=optimizerG,\n",
        "            optimizerD=optimizerD,\n",
        "            netG=netG,\n",
        "            netD=netD,\n",
        "            real_data=embeded,\n",
        "            label=data[1].float().to(device),  # True labels for real data\n",
        "            epoch=epoch,\n",
        "            i=i\n",
        "        )\n",
        "\n",
        "    # Evaluate the Discriminator on the test set after each epoch\n",
        "    auc_score = eval_auc(netD)\n",
        "\n",
        "    # Save model information for checkpointing or future selection\n",
        "    model_infos.append(get_model_info_dict(netD, epoch, auc_score))\n",
        "\n",
        "print('Train complete!')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siIb1c9UiRpl",
        "outputId": "10331e08-5d25-440c-c52b-0900d629fda8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0/5][0] Loss_D: 1.5199 Loss_G: 0.6363 D(x): 0.5222 D(G(z)): 0.5416 / 0.5296\n",
            "AUC: 0.9164\n",
            "[1/5][0] Loss_D: 3.7292 Loss_G: 0.0451 D(x): 0.4219 D(G(z)): 0.9583 / 0.9559\n",
            "AUC: 0.8109\n",
            "[2/5][0] Loss_D: 3.3039 Loss_G: 0.0608 D(x): 0.3424 D(G(z)): 0.9440 / 0.9410\n",
            "AUC: 0.8073\n",
            "[3/5][0] Loss_D: 2.5783 Loss_G: 0.1170 D(x): 0.2727 D(G(z)): 0.8955 / 0.8896\n",
            "AUC: 0.7745\n",
            "[4/5][0] Loss_D: 2.3788 Loss_G: 0.1374 D(x): 0.2344 D(G(z)): 0.8789 / 0.8717\n",
            "AUC: 0.8145\n",
            "Train complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the model checkpoint with the best AUC score\n",
        "max_auc_model_info = max(model_infos, key=lambda x: x['auc_score'])\n",
        "print(max_auc_model_info[\"auc_score\"])"
      ],
      "metadata": {
        "id": "_e_XhVtJocrZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61c241ee-6e55-4a1e-a235-6572813375dc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9163636363636364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best discriminator model based on AUC score\n",
        "model = Discriminator()  # Re-instantiate the Discriminator architecture\n",
        "model.load_state_dict(max_auc_model_info['model_state_dict'])  # Load the saved weights\n",
        "model.to(device)  # Move model to GPU or CPU\n",
        "model.eval()  # Set the model to evaluation mode (disable dropout, etc.)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn2yxVuRg7jr",
        "outputId": "78092400-b838-4a9d-ac1f-72c581efcd27"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=256, out_features=1, bias=True)\n",
              "    (3): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset class for inference (test set)\n",
        "class InferenceDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.texts = texts  # Store the list of input texts\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Return a single text sample at index idx\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the total number of samples\n",
        "        return len(self.texts)\n"
      ],
      "metadata": {
        "id": "xoI8pDe3ouau"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the inference dataset from the test text\n",
        "sub_dataset = InferenceDataset(src_test[\"text\"].tolist())  # Wrap the test texts in a custom dataset\n",
        "\n",
        "# Create the DataLoader for inference\n",
        "# We can use batch_size > 1 since there's no backpropagation\n",
        "inference_loader = DataLoader(sub_dataset, batch_size=16, shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "Po2fro2lorNE"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub_predictions = []  # Store predicted probabilities for the test set\n",
        "\n",
        "# Make sure the embedding model and discriminator are on the correct device\n",
        "embedding_model.to(device)\n",
        "model.to(device)\n",
        "model.eval()  # Set model to inference mode (no dropout, etc.)\n",
        "\n",
        "with torch.no_grad():  # Disable gradient computation for efficiency\n",
        "    for batch_texts in inference_loader:\n",
        "        # Tokenize the batch of raw texts\n",
        "        encoded = tokenizer(\n",
        "            batch_texts,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "            max_length=512\n",
        "        )\n",
        "\n",
        "        # Move all encoded tensors to the correct device (GPU or CPU)\n",
        "        encoded = {k: v.to(device) for k, v in encoded.items()}\n",
        "\n",
        "        # Get the [CLS] token embeddings from BERT\n",
        "        outputs = embedding_model(**encoded)\n",
        "        cls_embeddings = outputs.last_hidden_state[:, 0, :]  # Shape: (batch_size, 768)\n",
        "\n",
        "        # Run the discriminator on these embeddings to get probabilities\n",
        "        probs = model(cls_embeddings)  # Output: probability of being AI-generated\n",
        "\n",
        "        # Save predictions (move them to CPU and flatten)\n",
        "        sub_predictions.extend(probs.cpu().numpy().flatten())\n"
      ],
      "metadata": {
        "id": "qxZ78Q9wpsOt"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the final submission DataFrame\n",
        "sub_ans_df = pd.DataFrame({\n",
        "    \"id\": src_test[\"id\"],             # IDs from the test set\n",
        "    \"generated\": sub_predictions      # Predicted probabilities from the discriminator\n",
        "})\n",
        "\n",
        "# Display the first few rows of the submission file\n",
        "print(sub_ans_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4Uczzm9qonQ",
        "outputId": "589d2c7a-99d3-4495-add7-364df12571db"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         id  generated\n",
            "0  0000aaaa   0.465653\n",
            "1  1111bbbb   0.456055\n",
            "2  2222cccc   0.463177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conxlusion— GAN-based AI Text Detector\n",
        "\n",
        "This project implements a complete deep learning pipeline to detect AI-generated texts using a **Generative Adversarial Network (GAN)** and **BERT embeddings**.\n",
        "\n",
        "### 🛠️ Key stages:\n",
        "\n",
        "1. **Embedding extraction** from raw text using `bert-base-uncased`.\n",
        "2. **GAN architecture** with:\n",
        "   - A Generator to produce synthetic BERT-like vectors.\n",
        "   - A Discriminator to classify real vs. generated embeddings.\n",
        "3. **Training loop** alternating updates for both networks, optimized with BCE loss.\n",
        "4. **Evaluation** using AUC as the main metric.\n",
        "5. **Inference** on test samples and prediction formatting.\n",
        "\n",
        "### 📈 Result:\n",
        "\n",
        "- Best Discriminator model reached an **AUC of 0.916** — excellent performance in distinguishing AI vs. human-written content.\n"
      ],
      "metadata": {
        "id": "RM_ILv2_laCE"
      }
    }
  ]
}